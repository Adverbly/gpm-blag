---
title: Design and Intelligence
date: "2017-09-24T22:40:32.169Z"
layout: post
path: "/posts/design-smarts/"
category: "Design, Philosophy"
description: "Some thoughts on what an intelligence is, and how and why we should be consider the user's intelligence when designing products and systems."
---

We human beings tend to feel pretty special. And for good reason! We are by far the most successful and powerful life that we have met so far. If you compare our capabilities with those of any other animal, nothing even comes close. Why?

Our intelligence.

Okay so does this mean there is a direct correlation between intelligence and capabilities? **Hell no!** Our intelligence hasn't changed over the past several thousand years. That is to say, you could take a baby from a few thousand years ago, and raise him in today's society, and have him be just as capable as any of us. Or, the converse, if you took us as babies and raised us thousands of years ago, we would be just as capable as early humans were. 

Our capabilities increase over time despite constant intelligence. This is what truly separates us. No other animal is able to sustain this trend like we do. We can build on what others have done, *even if they were smarter than us.* Let me say that again: **even if they were smarter than us.** This trend does not require that we get any more intelligent. It only requires that we work to understand what has already been accomplished, and then seek to build out a little more. And as we build out more and more and more, the hard part becomes understanding what has already been accomplished. If someone cannot understand what has already been accomplished, it is largely as if it was *never accomplished in the first place.* It is therefore of monumental importance that when something is accomplished, it is made **simple** and **understandable to others**. In fact, the ability to simplify and communicate is in fact more important than intelligence itself. Let me illustrate this with an example. 

Lets say that raven progressive matrices are a good proxy for intelligence. They test out pattern recognition.

Here is an easy one:
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Raven_Matrix.svg/1024px-Raven_Matrix.svg.png" alt="Here is an easy one" style="width: 400px;"/>

Here is a less easy one:
<img src="https://iqpro.org/images/q/raven-progressive-matrics-iq-test-example3.png" alt="Here is a less easy one" style="width: 400px;"/>

Let's pretend that most people can solve the easy one, but noone can solve the less easy one. Now say we find someone who can solve the harder one, but is bad at explaining how they do it. They are very intelligent, but can't make what they do any easier for anyone else. When this person dies, *the whole of humanity goes back to being unable to solve the problem.*

Compare that to someone who finds out a new way to share how they solve the easy ones, such that now even more people will know how to solve it. When this person dies, the whole of humanity is *permanently better because of their accomplishment.*

The second was not as smart as the first, yet, they kept the intelligence snowball rolling where the first did not. **People who simplify understanding create the most value.** And this trend only increases as you increase the inequality between the capabilities of population.
**There is an interesting trade-off here that I won't get into, but you can imagine that some inequality might be healthy, where too much would not.

So where are we lacking? We have the internet after all! Wikipedia! That was supposed to be the great equalizer! Say you want to learn about the tensor product, but don't have a STEM university degree. 

**Good luck with that. -->** https://en.wikipedia.org/wiki/Tensor_product

Please put on your STEM-filtered glasses and give it a look. It is completely useless to most of humanity. Okay, but most of humanity doesn't need to know about tensor products, right? As we specialize, we get better at being able to ignore knowledge that we don't need. There are a several problems with this argument:

- For anyone who has to learn it, learning it is more difficult, wasting more of the learner's time
- Fewer people will be able to learn it, reducing the total amount that any one person can learn

And this doesn't only affect learning. The products and systems that we use are also overly difficult. Software tools, legal documents, complicated-to-assemble machines. The world is filled things that can only be understood by a very small subset of the population.

How can we do better? Well, we can start by reframing education. Right now we teach people how to be smarter in school. *But being smart is not responsible for humanity's success!* **Spreading** smarts is. So we should instead focus on teaching people to be better simplifiers, explainers, and teachers. And our lack of skills in this regard is very clear. After finishing something difficult, we often don't take enough time to try and simplify our work, and instead focus on trying to make more progress. Even worse, *we sometimes purposefully make it seem like what we do is more complicated than it really is.*

The damage done by poor explanation is massively underestimated. And yet, it is nothing compared to what might be to come based on the promises of artificial intelligence. We are all relatively close in intelligence, and yet, if we can't manage to communicate with each other, *imagine the difficulties we will face when artificial intelligences are co-existing with us and each other*. The intelligence mismatch between the smartest and stupidest human is likely dwarfed by the differences that we will see between artificial intelligences. **We need to develop systems and products that can work at any scale of intelligence.** **For anyone familiar with the cattle vs pets analogy in infrastructure, we need to be able to treat intelligent agents like pets, but work itself needs to be able to be accomplished by cattle.